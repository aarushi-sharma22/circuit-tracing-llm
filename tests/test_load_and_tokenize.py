from load_and_tokenize import (
    load_qwen_instruct_4bit,
    apply_qwen_chat_template,
    batch_tokenize,
    yes_no_token_ids,
)

def test_tokenize_and_render():
    model_id = "sshleifer/tiny-gpt2"  # tiny model for quick tests
    # Force GPTQ=True to skip bitsandbytes
    model, tokenizer = load_qwen_instruct_4bit(model_id, use_gptq=True)

    questions = ["Is stealing wrong?", "Is kindness good?"]

    # GPT-2 has no chat template â†’ fall back to raw questions
    try:
        rendered = apply_qwen_chat_template(tokenizer, questions)
    except (AttributeError, ValueError):
        rendered = questions

    assert len(rendered) == 2
    assert isinstance(rendered[0], str)

    batch = batch_tokenize(tokenizer, rendered)
    assert "input_ids" in batch
    assert batch["input_ids"].ndim == 2

    # yes/no ids may not exist cleanly on GPT-2, so guard
    try:
        yes_id, no_id = yes_no_token_ids(tokenizer)
        assert isinstance(yes_id, int)
        assert isinstance(no_id, int)
    except Exception:
        # acceptable for GPT-2 fallback
        yes_id, no_id = None, None
        assert yes_id is None and no_id is None
